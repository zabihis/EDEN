{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eehUu5GaqS6z"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from sklearn.neighbors import KernelDensity\n",
        "import torch\n",
        "from torch import nn\n",
        "import numpy as np\n",
        "import torch.utils.data as Data\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.metrics import (accuracy_score, roc_auc_score,\n",
        "                            matthews_corrcoef, average_precision_score,\n",
        "                            confusion_matrix, f1_score, precision_score,\n",
        "                            recall_score, #specificity_score,\n",
        "                            classification_report)\n",
        "from tqdm import tqdm\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!rm -rf /content/EDEN\n",
        "!git clone https://github.com/zabihis/EDEN/\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wTq1Vau8-rxR",
        "outputId": "5ccbf2b3-fd38-4f55-816d-4e3e7626f2e0"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'EDEN' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "wGQVUTABqXbx"
      },
      "outputs": [],
      "source": [
        "\n",
        "def evaluate_model(model, data_loader, criterion, device):\n",
        "    \"\"\"Evaluate model on given data loader and return loss and metrics\"\"\"\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    all_targets = []\n",
        "    all_probs = []\n",
        "    all_preds = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data, target in data_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            outputs = model(data)\n",
        "\n",
        "            running_loss += criterion(outputs, target.float().unsqueeze(1)).item()\n",
        "\n",
        "            probs = outputs.cpu().numpy().flatten()\n",
        "            preds = (probs > 0.5).astype(int)\n",
        "\n",
        "            all_targets.extend(target.cpu().numpy())\n",
        "            all_probs.extend(probs)\n",
        "            all_preds.extend(preds)\n",
        "\n",
        "    loss = running_loss / len(data_loader)\n",
        "    metrics = calculate_metrics(np.array(all_targets),\n",
        "                              np.array(all_preds),\n",
        "                              np.array(all_probs))\n",
        "    return loss, metrics\n",
        "\n",
        "\n",
        "def print_metrics(metrics, prefix=''):\n",
        "    \"\"\"Print formatted metrics\"\"\"\n",
        "    print(f\"{prefix}Accuracy: {metrics['accuracy']:.4f} | \"\n",
        "          f\"AUC: {metrics['auc']:.4f} | MCC: {metrics['mcc']:.4f} | \"\n",
        "          f\"AP: {metrics['ap']:.4f}\")\n",
        "    print(f\"{prefix}Sensitivity: {metrics['sensitivity']:.4f} | \"\n",
        "          f\"Specificity: {metrics['specificity']:.4f} | \"\n",
        "          f\"Precision: {metrics['precision']:.4f} | \"\n",
        "          f\"F1: {metrics['f1']:.4f}\")\n",
        "\n",
        "\n",
        "def calculate_metrics(y_true, y_pred, y_prob):\n",
        "    \"\"\"Calculate all required performance metrics\"\"\"\n",
        "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
        "    metrics = {\n",
        "        'accuracy': accuracy_score(y_true, y_pred),\n",
        "        'auc': roc_auc_score(y_true, y_prob),\n",
        "        'mcc': matthews_corrcoef(y_true, y_pred),\n",
        "        'ap': average_precision_score(y_true, y_prob),\n",
        "        'sensitivity': recall_score(y_true, y_pred),  # recall\n",
        "        'specificity': tn / (tn + fp), #specificity_score(y_true, y_pred),\n",
        "        'precision': precision_score(y_true, y_pred),\n",
        "        'f1': f1_score(y_true, y_pred)\n",
        "    }\n",
        "    return metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "78Y_aO2NqZ_1"
      },
      "outputs": [],
      "source": [
        "def EDNencoderMultiScale(seqs, kernel, bandwidthList, seqLenLimit):\n",
        "    Nseq = len(seqs)\n",
        "    Nscale=len(bandwidthList)\n",
        "    seq_len = len(seqs[0])\n",
        "    xspace = np.linspace(0, seqLenLimit-1, seqLenLimit)[:, np.newaxis]\n",
        "    seqsEncoded = np.zeros((Nseq, 4, seqLenLimit, Nscale), dtype='float32') #shape: [n_samples, seq_length, 4]\n",
        "\n",
        "    if abs(seqLenLimit-seq_len)>1:\n",
        "      print('* ATTENTION: the sequence length is ', seq_len, ' but you set the seqLenLimit=', seqLenLimit, '. This may affect the model performance.')\n",
        "      print()\n",
        "\n",
        "    for iseq in range(Nseq):  #seq loop\n",
        "        one_seq = seqs[iseq]\n",
        "        if len(one_seq)>seqLenLimit:\n",
        "            one_seq=one_seq[:seqLenLimit]\n",
        "        one_seq=one_seq.upper()\n",
        "        one_seq.replace(\"U\", \"T\")\n",
        "\n",
        "        # find Occurance\n",
        "        idxA=np.array(list(findstr(one_seq, 'A')))[:, np.newaxis]\n",
        "        idxT=np.array(list(findstr(one_seq, 'T')))[:, np.newaxis]\n",
        "        idxG=np.array(list(findstr(one_seq, 'G')))[:, np.newaxis]\n",
        "        idxC=np.array(list(findstr(one_seq, 'C')))[:, np.newaxis]\n",
        "\n",
        "        for iscale in range(Nscale):    #scale loop\n",
        "            bandwidth = bandwidthList[iscale]\n",
        "\n",
        "            sigA = EDNcalc(idxA, bandwidth, kernel, xspace)\n",
        "            sigT = EDNcalc(idxT, bandwidth, kernel, xspace)\n",
        "            sigG = EDNcalc(idxG, bandwidth, kernel, xspace)\n",
        "            sigC = EDNcalc(idxC, bandwidth, kernel, xspace)\n",
        "\n",
        "            sig = np.array([sigA, sigT, sigG, sigC])\n",
        "\n",
        "            seqsEncoded[iseq, :, :, iscale]=sig\n",
        "    print('EDN encoding done!', Nseq, \"x\", seqLenLimit)\n",
        "    return seqsEncoded\n",
        "\n",
        "\n",
        "def EDNcalc(idxPoints, bandwidth, kernel, xspace):\n",
        "    if len(idxPoints)>0:\n",
        "        kde_model = KernelDensity(kernel=kernel, bandwidth=bandwidth).fit(idxPoints)\n",
        "        EDN_sig = np.exp(kde_model.score_samples(xspace))*len(idxPoints)\n",
        "    else:\n",
        "        EDN_sig = np.zeros((xspace.shape[0]))\n",
        "    return EDN_sig\n",
        "\n",
        "\n",
        "def loadFile_gue(file_path):\n",
        "    # Read CSV into pandas DataFrame\n",
        "    df = pd.read_csv(file_path)\n",
        "    # Convert to NumPy array\n",
        "    seqs=df['sequence'].to_numpy()\n",
        "    labels=df['label'].to_numpy()\n",
        "    print(\"file loaded! data size: \", seqs.shape)\n",
        "    return seqs, labels\n",
        "\n",
        "\n",
        "def findstr(str, ch):\n",
        "    for i, ltr in enumerate(str):\n",
        "        if ltr == ch:\n",
        "            yield i"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "0uvr0vOVUO3G"
      },
      "outputs": [],
      "source": [
        "class Hybrid_CNN(nn.Module):\n",
        "    def __init__(self, seq_len=200, scales=4, channels=4):\n",
        "        super(Hybrid_CNN, self).__init__()\n",
        "        self.channels = channels  # Number of channels\n",
        "        self.seq_len = seq_len  # DNA sequence length\n",
        "        self.scales = scales  # Number of scales\n",
        "\n",
        "        # High-resolution branch (single scale)\n",
        "        self.high_res = nn.Sequential(\n",
        "            nn.Conv1d(in_channels=channels, out_channels=64,\\\n",
        "                       kernel_size=5, stride=1, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool1d(2),\n",
        "            nn.Dropout(0.2),\n",
        "\n",
        "            nn.Conv1d(in_channels=64, out_channels=128,\\\n",
        "                       kernel_size=5, stride=1, padding=2, ),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool1d(2),\n",
        "            nn.Dropout(0.2),\n",
        "\n",
        "            nn.Conv1d(in_channels=128, out_channels=128,\\\n",
        "                       kernel_size=5, stride=1, padding=2, ),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool1d(2),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.AdaptiveMaxPool1d(10)\n",
        "        )\n",
        "\n",
        "        # multi-resolution branch (multi scale)\n",
        "        # First conv layer processes\n",
        "        self.multiscale_conv1 = nn.Sequential(\n",
        "            nn.Conv2d(channels, 64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Dropout(0.2),\n",
        "        )\n",
        "        # sec conv layer processes\n",
        "        self.multiscale_conv2 = nn.Sequential(\n",
        "            nn.Conv2d(64, 128, kernel_size=5, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Dropout(0.2),\n",
        "        )\n",
        "        # sec conv layer processes\n",
        "        self.multiscale_conv3 = nn.Sequential(\n",
        "            nn.Conv1d(128, 128, kernel_size=5, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool1d(2),\n",
        "            nn.Dropout(0.2),\n",
        "        )\n",
        "        self.AdapMaxPool1d10=nn.AdaptiveMaxPool1d(10)\n",
        "        self.fc = nn.Sequential(nn.Linear(2*128*10, 256),\n",
        "                                nn.ReLU(),\n",
        "                                nn.Dropout(0.2)\n",
        "                                )\n",
        "        self.classifier = nn.Sequential(nn.Linear(256, 1),\n",
        "                                )\n",
        "    def forward(self,x):\n",
        "        # High-res branch (first scale only)\n",
        "        x_high = self.high_res(x[:,:,:,0]).squeeze(-1)\n",
        "        # first conv layer\n",
        "        x_multi = self.multiscale_conv1(x)\n",
        "        # sec conv layer\n",
        "        x_multi = self.multiscale_conv2(x_multi).squeeze(-1)\n",
        "        # 3rd conv layer\n",
        "        x_multi = self.multiscale_conv3(x_multi)\n",
        "        x_multi=self.AdapMaxPool1d10(x_multi)\n",
        "        # concat features x_high, x_multi\n",
        "        x = torch.cat([x_high, x_multi], dim=1)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "        out = self.classifier(x)\n",
        "        return out\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38dfacd2-b8d9-4e82-9baf-42518aeee0bf",
        "id": "5NV07yeVLIJG"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "* kernel:  cosine\n",
            "* Dataset:  mouse_tf1\n",
            "* Model:  Hybrid_CNN\n",
            "* encoding_name:  MSEDNSeq\n",
            "* pretrainedWeights_path:  /content/EDEN/models/Hybrid_CNN_mouse_tf1.pth\n",
            "cuda\n",
            "loading data file ...\n",
            "file loaded! data size:  (6745,)\n",
            "encodeing seqs ...\n",
            "EDN encoding done! 6745 x 100\n",
            "encoding done!\n",
            "Shape of X_test: (6745, 4, 100, 4)\n",
            "Load the weights...\n",
            "\n",
            "testing...\n",
            "\n",
            "Final Test Performance:\n",
            "Test Accuracy: 0.9007 | AUC: 0.9703 | MCC: 0.8028 | AP: 0.9735\n",
            "Test Sensitivity: 0.8701 | Specificity: 0.9312 | Precision: 0.9267 | F1: 0.8975\n"
          ]
        }
      ],
      "source": [
        "curPath = os.getcwd()\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "seqLenLimit=100\n",
        "dataset_name = 'mouse_tf1'   # human_tfX / mouse_tfX / human_prom_core_XXX / human_prom_300_XXX\n",
        "\n",
        "model_name='Hybrid_CNN'\n",
        "pretrainedWeights_path=curPath +'/EDEN/models/Hybrid_CNN_'+dataset_name+'.pth'\n",
        "data_path = curPath + \"/EDEN/datasets/\"\n",
        "testdata_filename=dataset_name+\"/test\"\n",
        "batch_size = 64\n",
        "kernel=\"cosine\"; bandwidthList=[0.5, 1.5, 3, 4.5]\n",
        "encoding_name='MSEDNSeq'\n",
        "\n",
        "\n",
        "#-disp info----------\n",
        "print('* kernel: ', kernel)\n",
        "print('* Dataset:  '+ data_path + dataset_name)\n",
        "print('* Model:  '+ model_name)\n",
        "print('* encoding_name:  '+ encoding_name)\n",
        "print('* pretrainedWeights_path:  '+ pretrainedWeights_path)\n",
        "print(device)\n",
        "\n",
        "#========load, prepare/encode data========\n",
        "print('loading data file ...')\n",
        "[seq_test, Y_test] = loadFile_gue(data_path + testdata_filename+'.csv') #load test file\n",
        "\n",
        "#--ENCODE DATA---\n",
        "print('encodeing seqs ...')\n",
        "X_test  = EDNencoderMultiScale(seq_test, kernel, bandwidthList, seqLenLimit)\n",
        "print('encoding done!')\n",
        "\n",
        "#-disp data info-------------\n",
        "print(\"Shape of X_test:\", X_test.shape)\n",
        "\n",
        "#--Prepare DataLoaders--\n",
        "test_dataset = Data.TensorDataset((torch.from_numpy(X_test)).to(torch.float32), torch.LongTensor(Y_test))\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "#=======Initialize Model=========\n",
        "global model\n",
        "exec('model = '+model_name+'(seq_len=seqLenLimit, scales=4, channels=4)')\n",
        "model.to(device) # Move model to the device\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "#-load model weights-------------\n",
        "print('Load the weights...')\n",
        "model.load_state_dict(torch.load(pretrainedWeights_path))\n",
        "\n",
        "#============TEST==================\n",
        "print('\\ntesting...')\n",
        "_, test_metrics = evaluate_model(model, test_loader, criterion, device)\n",
        "\n",
        "print('\\nFinal Test Performance:')\n",
        "print_metrics(test_metrics, prefix='Test ')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}